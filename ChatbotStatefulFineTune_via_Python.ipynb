{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa1f0a5f",
   "metadata": {},
   "source": [
    "# Ask ChatGPT via Python (Translation Example)\n",
    "\n",
    "This notebook demonstrates how to call the OpenAI API from Python to generate text and translate it using ChatGPT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a8c90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "import requests\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc7ff73",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_location='C:\\\\Users\\\\user\\\\Desktop\\\\Coding\\\\OpenAPI_Key.txt'\n",
    "\n",
    "with open(key_location, 'r') as file:\n",
    "    key=file.readline().strip()\n",
    "\n",
    "client=OpenAI(api_key=key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd3d0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_file(file:str):\n",
    "    url=\"https://api.openai.com/v1/files\"\n",
    "    headers={\n",
    "        \"Authorization\": f\"Bearer {key}\"\n",
    "    }\n",
    "    files={ \"file\": open(file, \"rb\") }\n",
    "    data={ \"purpose\": \"fine-tune\" }\n",
    "    response=requests.post(url, headers=headers, files=files, data=data, timeout=20)\n",
    "    if response.status_code==200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(\"Request failed with status code:\", response.status_code)\n",
    "        raise Exception(f\"File upload failed with status code {response.status_code}: {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96241141",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fine_tuning_model(file_id):\n",
    "    url=\"https://api.openai.com/v1/fine_tuning/jobs\"\n",
    "    headers={\n",
    "        \"Authorization\": f\"Bearer {key}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    data={\n",
    "        \"training_file\": file_id,\n",
    "        \"model\": \"gpt-4.1-nano-2025-04-14\",\n",
    "        ##\"safety_identifiers\": []\n",
    "    }\n",
    "    response=requests.post(url, headers=headers, json=data, timeout=20)\n",
    "    \n",
    "    if response.status_code==200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(\"Request failed with status code:\", response.status_code)\n",
    "        raise Exception(f\"Fine tuning failed with status code {response.status_code}: {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353ba36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_tuning_model(fine_tune_id):\n",
    "    url=f\"https://api.openai.com/v1/fine_tuning/jobs/{fine_tune_id}\"\n",
    "    headers={\n",
    "        \"Authorization\": f\"Bearer {key}\",\n",
    "    }\n",
    "    response=requests.get(url, headers=headers, timeout=600)\n",
    "    \n",
    "    if response.status_code==200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(\"Request failed with status code:\", response.status_code)\n",
    "        raise Exception(f\"Retrieve fine tuning failed with status code {response.status_code}: {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735cdbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#upload_result=upload_file(\"./data/fine_tune_data.jsonl\")\n",
    "#print(upload_result)\n",
    "#uploaded_file_id=upload_result['id']\n",
    "#print(uploaded_file_id)\n",
    "#with open('./data/fine_tune_data.jsonl') as f:\n",
    "#    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74eb8047",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fine_tune_model_result=fine_tuning_model(uploaded_file_id)\n",
    "#fine_tune_model_id=fine_tune_model_result['id']\n",
    "#print(fine_tune_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e128275",
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tuned_model=\"\"\n",
    "fine_tune_model_id=\"ftjob-PQ6agBwQUhgF1ee2kpDOpQCE\"\n",
    "\n",
    "while True:\n",
    "    fine_tune_object=retrieve_tuning_model(fine_tune_model_id)\n",
    "    print(fine_tune_object['status'])\n",
    "    if fine_tune_object['status']==\"succeeded\":\n",
    "        fine_tuned_model=fine_tune_object['fine_tuned_model']\n",
    "        break\n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbae33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(str(fine_tuned_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8cbc097",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_message=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba4fd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_chat_request(prompt, fine_tuned_model):\n",
    "    chat_message.append({\"role\": \"user\", \"content\": prompt})\n",
    "    response=client.chat.completions.create(\n",
    "        model=fine_tuned_model,\n",
    "        messages=chat_message,\n",
    "        temperature=0.7\n",
    "    )\n",
    "    chat_message.append({\"role\": \"assistant\", \"content\": response.choices[0].message.content})\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810a7b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Hellow and welcome to the Chatbot! How can I help you today?\")\n",
    "system_message=\"You are a helpful assistant.\"\n",
    "chat_message.append({\"role\": \"system\", \"content\": system_message})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffaa44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    print(\"User Prompt: \")\n",
    "    user_prompt=input()\n",
    "    print(\"User: \" + user_prompt)\n",
    "    response=process_chat_request(user_prompt, fine_tuned_model)\n",
    "    print(\"Chatbot: \" + response)\n",
    "    print(\" \")\n",
    "    print(\" \")\n",
    "    \n",
    "    if user_prompt.lower() in ['exit', 'quit', 'bye']:\n",
    "        print(\"Chatbot: Goodbye!\")\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
